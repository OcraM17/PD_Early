{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Subject_Characteristics/PPMI_Baseline_Data_02Jul2018.csv')\n",
    "PD_patlist=x[x['APPRDX']==1]['PATNO']\n",
    "per='V04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=pd.DataFrame()\n",
    "year['PATNO']=PD_patlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Medical_History/Vital_Signs.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.iloc[:,np.r_[2,6:9,10:16]]\n",
    "x['BMI']=x['WGTKG']/((x['HTCM']/100)*(x['HTCM']/100))\n",
    "year=year.merge(x.loc[:,['PATNO','BMI','SYSSUP','HRSUP']],on='PATNO',how='left')\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Motor_Assessments/MDS_UPDRS_Part_I.csv')\n",
    "y=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Motor_Assessments/MDS_UPDRS_Part_I__Patient_Questionnaire.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "\n",
    "y=y[y['PATNO'].isin(PD_patlist)]\n",
    "y=y[y['EVENT_ID']==per]\n",
    "x=x.iloc[:,np.r_[2,7:13]]\n",
    "y=y.iloc[:,np.r_[2,7:14]]\n",
    "x=x.merge(y,how='outer',on='PATNO')\n",
    "x['Cognitive']=x.loc[:,['NP1COG','NP1HALL','NP1DPRS','NP1ANXS','NP1APAT','NP1DDS']].sum(axis=1,skipna=False)\n",
    "x['Sleep']=x.loc[:,['NP1SLPN','NP1SLPD']].sum(axis=1,skipna=False)\n",
    "x['Autonomic_Nervous_System']=x.loc[:,['NP1URIN','NP1CNST','NP1LTHD','NP1FATG']].sum(axis=1,skipna=False)\n",
    "x['Total_UPDRS1']=x.loc[:,'NP1COG':'NP1FATG'].sum(axis=1,skipna=False)\n",
    "\n",
    "year=year.merge(x.iloc[:,np.r_[0,14:18]],on='PATNO',how='left')\n",
    "\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Motor_Assessments/MDS_UPDRS_Part_II__Patient_Questionnaire.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x['Bulbar']=x.loc[:,['NP2SPCH','NP2SALV','NP2SWAL','NP2EAT']].sum(axis=1,skipna=False)\n",
    "x['Common_daily_act']= x.loc[:,['NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB']].sum(axis=1,skipna=False)\n",
    "x['Bed']=x.loc[:,['NP2TURN','NP2RISE']].sum(axis=1,skipna=False)\n",
    "x['Gait']=x.loc[:,['NP2WALK','NP2FREZ']].sum(axis=1,skipna=False)\n",
    "x['Total_UPDRS2']=x.loc[:,'NP2SPCH':'NP2FREZ'].sum(axis=1,skipna=False)\n",
    "x=x.loc[:,['PATNO','Bulbar','Common_daily_act','Bed','Gait','Total_UPDRS2']]\n",
    "year=year.merge(x,on='PATNO',how='left')\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Motor_Assessments/MDS_UPDRS_Part_III.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x[x['PAG_NAME']=='NUPDRS3']\n",
    "x=x.iloc[:,np.r_[2,11:44]]\n",
    "x['Axial_Sub_1']=x.loc[:,['NP3SPCH','NP3FACXP','NP3RIGN',\n",
    "                     'NP3RISNG','NP3GAIT','NP3FRZGT',\n",
    "                     'NP3PSTBL','NP3POSTR','NP3BRADY','NP3RTALJ']].sum(axis=1,skipna=False)\n",
    "x['Axial_Sub_2']=x.loc[:,['NP3RISNG','NP3GAIT','NP3FRZGT',\n",
    "                     'NP3PSTBL','NP3POSTR','NP3BRADY']].sum(axis=1,skipna=False)\n",
    "x['Limb_Rig_Sub']=x.loc[:,['NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL']].sum(axis=1,skipna=False)\n",
    "x['Limb_Brady_Sub']=x.loc[:,['NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL',\n",
    "                             'NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL',\n",
    "                            'NP3LGAGR','NP3LGAGL']].sum(axis=1,skipna=False)\n",
    "x['Tremor_Sub']=x.loc[:,['NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU',\n",
    "                          'NP3RTALU','NP3RTARL','NP3RTALL','NP3RTCON']].sum(axis=1,skipna=False)\n",
    "x['Rest_Tremor_Sub']=x.loc[:,['NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTCON']].sum(axis=1,skipna=False)\n",
    "x['Append_Sub']=x.loc[:,['Limb_Rig_Sub','Limb_Brady_Sub','Tremor_Sub']].sum(axis=1,skipna=False)\n",
    "x['Left_Motor_Score']=x.loc[:,['NP3RIGLU','NP3RIGLL','NP3FTAPL','NP3HMOVL',\n",
    "                                 'NP3PRSPL','NP3TTAPL','NP3LGAGL','NP3PTRML',\n",
    "                                 'NP3KTRML','NP3RTALU','NP3RTALL']].sum(axis=1,skipna=False)\n",
    "x['Right_Motor_Score']=x.loc[:,['NP3RIGRU','PN3RIGRL','NP3FTAPR','NP3HMOVR',\n",
    "                                  'NP3PRSPR','NP3TTAPR','NP3LGAGR','NP3PTRMR',\n",
    "                                  'NP3KTRMR','NP3RTARU','NP3RTARL']].sum(axis=1,skipna=False)\n",
    "x['Diff']=x['Left_Motor_Score']-x['Right_Motor_Score']\n",
    "x['Asymmetry']=np.abs(x['Diff'])\n",
    "\n",
    "x['Total_UPDRS3']=x.loc[:,'NP3SPCH':'NP3RTCON'].sum(axis=1,skipna=False)\n",
    "\n",
    "x=x.loc[:,['PATNO','Axial_Sub_1','Axial_Sub_2','Limb_Rig_Sub','Limb_Brady_Sub','Tremor_Sub','Rest_Tremor_Sub',\n",
    "          'Append_Sub','Left_Motor_Score','Right_Motor_Score','Diff','Asymmetry','Total_UPDRS3']]\n",
    "\n",
    "year=year.merge(x,on='PATNO',how='left')\n",
    "year['Total_UPDRS']=year['Total_UPDRS1']+year['Total_UPDRS2']+year['Total_UPDRS3']\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year['Total_UPDRS3'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Motor_Assessments/Modified_Schwab_+_England_ADL.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.loc[:,['PATNO','MSEADLG']]\n",
    "year=year.merge(x,on='PATNO',how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/Neurophysiological/Benton_Judgment_of_Line_Orientation.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.loc[:,['PATNO','DVS_JLO_MSSAE']]\n",
    "year=year.merge(x,on='PATNO',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/Sleep_Disorder/Epworth_Sleepiness_Scale.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x['Epworth_SUM']=x.loc[:,'ESS1':'ESS8'].sum(axis=1,skipna=False)\n",
    "x=x.loc[:,['PATNO','Epworth_SUM']]\n",
    "year=year.merge(x,on='PATNO',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/NeuroBehavioral/Geriatric_Depression_Scale__Short_.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.iloc[:,np.r_[2,6:21,]]\n",
    "no=['GDSSATIS', 'GDSGSPIR', 'GDSHAPPY', 'GDSALIVE', 'GDSENRGY']\n",
    "x['GDS_SUM']=np.zeros(len(x))\n",
    "for i in no:\n",
    "    x[i]=1-x[i]\n",
    "x['GDS_SUM']=x.loc[:,'GDSSATIS':'GDSBETER'].sum(axis=1,skipna=False)\n",
    "x=x.loc[:,['PATNO','GDS_SUM']]\n",
    "year=year.merge(x,on='PATNO',how='left')\n",
    "year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/Neurophysiological/Hopkins_Verbal_Learning_Test.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.iloc[:,np.r_[2,16]]\n",
    "year=year.merge(x,on='PATNO',how='left')\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/Neurophysiological/Letter_-_Number_Sequencing__PD_.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.loc[:,['PATNO','DVS_LNS']]\n",
    "year=year.merge(x,on='PATNO',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/Neurophysiological/Montreal_Cognitive_Assessment__MoCA_.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.loc[:,['PATNO','MCATOT']]\n",
    "year=year.merge(x,on='PATNO',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/NeuroBehavioral/QUIP_Current_Short.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.iloc[:,np.r_[2,7:20]]\n",
    "x['QUIP_Sum']=x.loc[:,'TMGAMBLE':'CNTRLDSM'].sum(axis=1,skipna=False)\n",
    "x['QUIP_Buying']=x.loc[:,['TMBUY','CNTRLBUY']].sum(axis=1,skipna=False)\n",
    "x['QUIP_Eating']=x.loc[:,['TMEAT','CNTRLEAT']].sum(axis=1,skipna=False)\n",
    "x['QUIP_Gamble']=x.loc[:,['TMGAMBLE','CNTRLGMB']].sum(axis=1,skipna=False)\n",
    "x['QUIP_Hobbies']=x.loc[:,['TMTORACT']].sum(axis=1,skipna=False)\n",
    "x['QUIP_Punding']=x.loc[:,['TMTMTACT']].sum(axis=1,skipna=False)\n",
    "x['QUIP_Sex']=x.loc[:,['TMSEX','CNTRLSEX']].sum(axis=1,skipna=False)\n",
    "x['QUIP_Driving']=x.loc[:,['TMTRWD']].sum(axis=1,skipna=False)\n",
    "                          \n",
    "x=x.loc[:,['PATNO','QUIP_Sum']]\n",
    "year=year.merge(x,on='PATNO',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/Sleep_Disorder/REM_Sleep_Disorder_Questionnaire.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.iloc[:,np.r_[2,7:28]]\n",
    "x['REM_Sum']=x.loc[:,'DRMVIVID':'CNSOTH'].sum(axis=1,skipna=False)\n",
    "x=x.loc[:,['PATNO','REM_Sum']]\n",
    "year=year.merge(x,on='PATNO',how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/Autonomic/SCOPA-AUT.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "for i in x.loc[:,'SCAU1':'SCAU21'].columns:\n",
    "    x[i]=x[i].replace(9,3)\n",
    "for i in x.loc[:,'SCAU22':'SCAU25'].columns: \n",
    "    x[i]=x[i].replace(9,0)\n",
    "x['SCOPA_TOT']=x.loc[:,'SCAU1':'SCAU25'].sum(axis=1)\n",
    "x['SCOPA_Gastro']=x.loc[:,'SCAU1':'SCAU7'].sum(axis=1)\n",
    "x['SCOPA_Urinary']=x.loc[:,'SCAU8':'SCAU13'].sum(axis=1)\n",
    "x['SCOPA_Cardio']=x.loc[:,'SCAU14':'SCAU16'].sum(axis=1)\n",
    "x['SCOPA_Pupillomotor']=x.loc[:,'SCAU19']\n",
    "x['SCOPA_Thermoreg']=x.loc[:,['SCAU17','SCAU18','SCAU20','SCAU21']].sum(axis=1)\n",
    "x['SCOPA_Sex']=x.loc[:,'SCAU22':'SCAU25'].sum(axis=1)\n",
    "x=x.loc[:,['PATNO','SCOPA_TOT']]\n",
    "year=year.merge(x,on='PATNO',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/NeuroBehavioral/State-Trait_Anxiety_Inventory.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.iloc[:,np.r_[2,6:46]]\n",
    "rev=[1, 2, 5, 8, 10, 11, 15, 16, 19, 20, 21, 23, 26, 27, 30, 33, 34, 36, 39]\n",
    "for (j,i) in zip(x.iloc[:,1:].columns,range(1,41)):\n",
    "    if i in rev:\n",
    "        x[j]=5-x[j]\n",
    "x['STAI_Sum_S']=x.loc[:,'STAIAD1':'STAIAD20'].sum(axis=1,skipna=False)\n",
    "x['STAI_Sum_T']=x.loc[:,'STAIAD21':'STAIAD40'].sum(axis=1,skipna=False)\n",
    "x['STAI_Sum']=x['STAI_Sum_S']+x['STAI_Sum_T']\n",
    "x=x.loc[:,['PATNO','STAI_Sum']]\n",
    "year=year.merge(x,on='PATNO',how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv('/Users/marco/Documents/Thesis/PPMI_Dataset/Non-Motor-Asses/Neurophysiological/Symbol_Digit_Modalities.csv')\n",
    "x=x[x['PATNO'].isin(PD_patlist)]\n",
    "x=x[x['EVENT_ID']==per]\n",
    "x=x.loc[:,['PATNO','DVT_SDM']]\n",
    "year=year.merge(x,on='PATNO',how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=year.dropna()\n",
    "year=year.drop(columns=['Diff','Left_Motor_Score','Right_Motor_Score','Asymmetry',\n",
    "                              'Total_UPDRS1','Total_UPDRS2','Total_UPDRS3',\n",
    "                        'Total_UPDRS','Axial_Sub_2','Rest_Tremor_Sub','Limb_Brady_Sub'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year.to_csv('/Users/marco/Documents/Thesis/Thesis_Notebook/1_yr_Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BL=pd.read_csv('BL_features.csv').drop(columns='Unnamed: 0')\n",
    "#BL=pd.read_csv('BL_features_1.csv').drop(columns='Unnamed: 0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BL=BL.merge(year,on='PATNO',how='left')\n",
    "BL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BL=BL.dropna()\n",
    "BL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#BL['Diff_2_1']=BL['Total_UPDRS3_y']-BL['Total_UPDRS3_x']\n",
    "#BL['Diff_2_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BL=BL.drop(columns=['Diff_y','Left_Motor_Score_y','Right_Motor_Score_y','Asymmetry_y',\n",
    "#                              'Total_UPDRS1_y','Total_UPDRS2_y','Total_UPDRS3_y',\n",
    "#                        'Total_UPDRS_y','Axial_Sub_2_y','Rest_Tremor_Sub_y','Limb_Brady_Sub_y'])\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "feat=['BMI_x','SYSSUP_x','HRSUP_x','Cognitive_x','Sleep_x','Autonomic_Nervous_System_x',\n",
    "      'Bulbar_x','Common_daily_act_x','Bed_x','Gait_x','Axial_Sub_1_x','Limb_Rig_Sub_x',\n",
    "      'Tremor_Sub_x','Append_Sub_x','MSEADLG_x','DVS_JLO_MSSAE_x','Epworth_SUM_x',\n",
    "      'GDS_SUM_x','DVT_TOTAL_RECALL_x','DVS_LNS_x','MCATOT_x','QUIP_Sum_x','REM_Sum_x',\n",
    "      'SCOPA_TOT_x','STAI_Sum_x','DVT_SDM_x']\n",
    "for j in feat:\n",
    "    BL['Diff'+j.split('_x')[0]]=BL[j.split('_x')[0]+'_y']-BL[j]\n",
    "    \n",
    "BL\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "feat=['BMI_x','SYSSUP_x','HRSUP_x','Cognitive_x','Sleep_x','Autonomic_Nervous_System_x',\n",
    "      'Bulbar_x','Common_daily_act_x','Bed_x','Gait_x','Axial_Sub_1_x','Limb_Rig_Sub_x',\n",
    "      'Tremor_Sub_x','Append_Sub_x','MSEADLG_x','DVS_JLO_MSSAE_x','Epworth_SUM_x',\n",
    "      'GDS_SUM_x','DVT_TOTAL_RECALL_x','DVS_LNS_x','MCATOT_x','QUIP_Sum_x','REM_Sum_x',\n",
    "      'SCOPA_TOT_x','STAI_Sum_x','DVT_SDM_x']\n",
    "for j in feat:\n",
    "    BL['Diff'+j.split('_x')[0]+'2_BL']=BL[j.split('_x')[0]]-BL[j]\n",
    "    \n",
    "BL\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "feat=['BMI_x','SYSSUP_x','HRSUP_x','Cognitive_x','Sleep_x','Autonomic_Nervous_System_x',\n",
    "      'Bulbar_x','Common_daily_act_x','Bed_x','Gait_x','Axial_Sub_1_x','Limb_Rig_Sub_x',\n",
    "      'Tremor_Sub_x','Append_Sub_x','MSEADLG_x','DVS_JLO_MSSAE_x','Epworth_SUM_x',\n",
    "      'GDS_SUM_x','DVT_TOTAL_RECALL_x','DVS_LNS_x','MCATOT_x','QUIP_Sum_x','REM_Sum_x',\n",
    "      'SCOPA_TOT_x','STAI_Sum_x','DVT_SDM_x']\n",
    "for j in feat:\n",
    "    BL['Diff'+j.split('_x')[0]+'2_1']=BL[j.split('_x')[0]]-BL[j.split('_x')[0]+'_y']\n",
    "    \n",
    "BL\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=BL['Class']\n",
    "X=BL.drop(columns='Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "plt.scatter(X['Diff_BL_1yr'],Y)\n",
    "#np.array(Y['Class'].values)\n",
    "#pearsonr(X['DiffBulbar'].values,Y['Class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['gen']==2]['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=X.iloc[:,np.r_[1:39,91:117,142:169]]\n",
    "#X=X.iloc[:,np.r_[1:36,91:118,144:170]]\n",
    "X=X.iloc[:,np.r_[1:38,64:90]]\n",
    "X.info()\n",
    "#Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,5,8]\n",
    "b=[1,2,3,1]\n",
    "from scipy.stats import spearmanr\n",
    "spearmanr(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=X[X.isna().any(axis=1)].index\n",
    "X=X.drop(index=ind).reset_index().drop(columns='index')\n",
    "Y=Y.drop(index=ind).reset_index().drop(columns='index')\n",
    "\n",
    "\n",
    "    \n",
    "#Standardization\n",
    "\n",
    "for col in X.columns:\n",
    "    if col=='gen' or col=='DOMSIDE':\n",
    "        continue\n",
    "    else:\n",
    "        X[col]=(X[col]-X[col].mean())/X[col].std()\n",
    "        \n",
    "#Correlation analysis\n",
    "corr=X.corr('spearman').abs()\n",
    "sns.heatmap(X.corr())\n",
    "plt.savefig('heat_1yr')\n",
    "feat=list(X.columns)\n",
    "drop=[]\n",
    "for i in range(len(corr)):\n",
    "    for j in range(i+1,len(corr)):\n",
    "            if np.abs(corr.iloc[i,j]) >0.8:\n",
    "                print(feat[i],feat[j],corr.iloc[i,j])\n",
    "                drop.append(feat[i])\n",
    "                drop.append(feat[j])\n",
    "drop=list(dict.fromkeys(drop))\n",
    "keep=['age','Axial_Sub_1_x','Append_Sub_x','Tremor_Sub_x','Diff_BL_1yr']\n",
    "drop=list(set(drop)-set(keep))\n",
    "X=X.drop(columns=drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y[Y['Class']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[i for i in range(57)]\n",
    "l.remove(0)\n",
    "l.remove(3)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1,stratify=Y,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import f1_score,confusion_matrix,precision_score,balanced_accuracy_score,recall_score,accuracy_score,roc_auc_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif,RFE,SelectFpr,chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,LeaveOneOut\n",
    "from sklearn.feature_selection import mutual_info_classif,GenericUnivariateSelect\n",
    "from imblearn.over_sampling import SMOTENC,BorderlineSMOTE,ADASYN,SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from scipy.stats import mannwhitneyu,kruskal,f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[RandomForestClassifier(n_estimators=10,n_jobs=-1,bootstrap=True,class_weight='balanced_subsample'),\n",
    "       GaussianNB(),LogisticRegression(class_weight='balanced'),DummyClassifier(strategy='most_frequent'),\n",
    "        SGDClassifier('log',learning_rate='adaptive',eta0=0.01,class_weight='balanced'), DecisionTreeClassifier(class_weight='balanced'),\n",
    "        AdaBoostClassifier(n_estimators=10),GradientBoostingClassifier(n_estimators=10)]\n",
    "\n",
    "model_names=['RF','GNB','LOG_Reg','Dummy','SGDClass','DecTree','ADA','GBC']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.1,stratify=Y,random_state=0,shuffle=True)\n",
    "models=[LogisticRegression(class_weight='balanced')]\n",
    "\n",
    "model_names=['LOG_Reg']\n",
    "\n",
    "n_feat=[3,6,8,10]\n",
    "\n",
    "for f in n_feat:\n",
    "    print('\\nN Feat:',f)\n",
    "    for model,model_name in zip(models,model_names):\n",
    "        acc,f1,p,r,accb,roc = [],[],[],[],[],[]\n",
    "        y_p=[]\n",
    "        y_t=[]\n",
    "        print(model_name)\n",
    "        loo=LeaveOneOut()\n",
    "        feat={key:0 for key in X.columns}\n",
    "        for train_index, test_index in loo.split(X_train, y_train):\n",
    "            X_train_K, X_test_K = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "            y_train_K, y_test_K = y_train.iloc[train_index,:], y_train.iloc[test_index,:]\n",
    "            # select best features on training \n",
    "\n",
    "            rank={key:0 for key in X_train.columns}\n",
    "            for j in X_train.columns:\n",
    "                rank[j]=mannwhitneyu(X_train_K[y_train_K['Class']==0][j],X_train_K[y_train_K['Class']==1][j])[1]\n",
    "\n",
    "            rank={k: v for k, v in sorted(rank.items(), key=lambda item: item[1],reverse=False)}  \n",
    "            support=list(rank.keys())[0:f]\n",
    "            \n",
    "            #selector=RFE(LogisticRegression(class_weight='balanced'),f)\n",
    "            #selector=selector.fit(X_train_K,y_train_K)\n",
    "            #support=selector.support_\n",
    "            for j in X_train_K.loc[:,support].columns.to_list():\n",
    "                feat[j]+=1\n",
    "            #keep only selected features\n",
    "            X_train_K = X_train_K.loc[:,support]\n",
    "            X_test_K = X_test_K.loc[:,support]\n",
    "            \n",
    "            oversample=SMOTE(sampling_strategy=1,k_neighbors=5,random_state=0)\n",
    "            under=RandomUnderSampler(0.5,random_state=1)\n",
    "            #X_train_K,y_train_K=under.fit_resample(X_train_K, y_train_K)\n",
    "            #X_train_K, y_train_K = oversample.fit_resample(X_train_K, y_train_K)\n",
    "\n",
    "\n",
    "\n",
    "            model = model.fit(X_train_K,y_train_K.values.ravel())\n",
    "\n",
    "            y_pred = model.predict(X_test_K)\n",
    "            y_p.append(np.asscalar(y_pred))\n",
    "            y_t.append(np.asscalar(y_test_K.values))\n",
    "            \n",
    "            #acc.append(accuracy_score(y_test_K,y_pred))\n",
    "            #f1.append(f1_score(y_test_K,y_pred))\n",
    "            #p.append(precision_score(y_test_K,y_pred))\n",
    "            #r.append(recall_score(y_test_K,y_pred))\n",
    "            #accb.append(balanced_accuracy_score(y_test_K,y_pred))\n",
    "            #try:\n",
    "            #    roc.append(roc_auc_score(y_test_K,y_pred))\n",
    "            #except:\n",
    "            #    roc.append(np.nan)\n",
    "        print('TRAIN')\n",
    "        feat={k: v for k, v in sorted(feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "        print(feat)\n",
    "        print(accuracy_score(y_t,y_p))\n",
    "        print(f1_score(y_t,y_p))\n",
    "        print(precision_score(y_t,y_p))\n",
    "        print(recall_score(y_t,y_p))\n",
    "        print(balanced_accuracy_score(y_t,y_p))\n",
    "        print(roc_auc_score(y_t,y_p))\n",
    "        print(confusion_matrix(y_t,y_p))\n",
    "        \n",
    "        X_train_ov=X_train.loc[:,list(feat.keys())[0:f]]\n",
    "        X_test_ov=X_test.loc[:,list(feat.keys())[0:f]]\n",
    "        \n",
    "        X_train_ov,y_train_ov=under.fit_resample(X_train_ov, y_train)\n",
    "        X_train_ov, y_train_ov = oversample.fit_resample(X_train_ov, y_train_ov)\n",
    "        \n",
    "        model=model.fit(X_train_ov,y_train_ov)\n",
    "        y_pred=model.predict(X_test_ov)\n",
    "        \n",
    "        print('TEST')\n",
    "        print(accuracy_score(y_test,y_pred))\n",
    "        print(f1_score(y_test,y_pred))\n",
    "        print(precision_score(y_test,y_pred))\n",
    "        print(recall_score(y_test,y_pred))\n",
    "        print(balanced_accuracy_score(y_test,y_pred))\n",
    "        print(roc_auc_score(y_test,y_pred))\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        \n",
    "        #print('Acc mean',np.mean(acc))    \n",
    "        #print('F1 mean',np.mean(f1))\n",
    "        #print('Precision mean',np.mean(p))\n",
    "        #print('Recall mean',np.mean(r))\n",
    "        #print('Balance Acc mean',np.mean(accb))\n",
    "        #try:\n",
    "        #    print('Roc AUC:',np.mean(roc))\n",
    "        #except:\n",
    "        #    print('ROC AUC: Nan')\n",
    "        #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Define dictionary to store our rankings\n",
    "ranks = {}\n",
    "# Create our function which stores the feature rankings to the ranks dictionary\n",
    "def ranking(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x,2), ranks)\n",
    "    return dict(zip(names, ranks))\n",
    "\n",
    "def feature_selection(n,X,y):\n",
    "    \n",
    "    colnames = list(X.columns)\n",
    "\n",
    "    # Construct our Linear Regression model\n",
    "    #lr = LinearRegression()\n",
    "    #lr.fit(X,y.values.ravel())\n",
    "    \n",
    "    #stop the search when only the last feature is left\n",
    "    #rfe = RFE(lr, n_features_to_select=1, verbose =3 )\n",
    "    #rfe.fit(X,y.values.ravel())\n",
    "    #ranks[\"RFE\"] = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)\n",
    "\n",
    "    # Using Linear Regression\n",
    "    #lr = LinearRegression()\n",
    "    #lr.fit(X,y.values.ravel())\n",
    "    #ranks[\"LinReg\"] = ranking(np.abs(lr.coef_), colnames)\n",
    "\n",
    "    # Using Ridge \n",
    "    ridge = Ridge(alpha = 7)\n",
    "    ridge.fit(X_train_K,y_train_K.values.ravel())\n",
    "    ranks['Ridge'] = ranking(np.abs(ridge.coef_), colnames)\n",
    "\n",
    "    # Using Lasso\n",
    "    lasso = Lasso(alpha=.05)\n",
    "    lasso.fit(X, y.values.ravel())\n",
    "    ranks[\"Lasso\"] = ranking(np.abs(lasso.coef_), colnames)\n",
    "    \n",
    "    # Random Forest\n",
    "    rf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=0)\n",
    "    rf.fit(X,y.values.ravel())\n",
    "    ranks[\"RF\"] = ranking(rf.feature_importances_, colnames)\n",
    "\n",
    "    # Create empty dictionary to store the mean value calculated from all the scores\n",
    "    r = {}\n",
    "    for name in colnames:\n",
    "        r[name] = round(np.mean([ranks[method][name] for method in ranks.keys()]), 2)\n",
    "\n",
    "    methods = sorted(ranks.keys())\n",
    "    ranks[\"Mean\"] = r\n",
    "    methods.append(\"Mean\")\n",
    "\n",
    "    #print(\"\\t%s\" % \"\\t\".join(methods))\n",
    "    #for name in colnames:\n",
    "        #print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                             #[ranks[method][name] for method in methods]))))\n",
    "\n",
    "    # Put the mean scores into a Pandas dataframe\n",
    "    meanplot = pd.DataFrame(list(ranks[\"Lasso\"].items()), columns= ['Feature','Ranking'])\n",
    "\n",
    "    # Sort the dataframe\n",
    "    meanplot = meanplot.sort_values('Ranking', ascending=False)\n",
    "\n",
    "    # Let's plot the ranking of the features\n",
    "    sns.factorplot(x=\"Ranking\", y=\"Feature\", data = meanplot, kind=\"bar\", \n",
    "                   size=14, aspect=1.9, palette='coolwarm')\n",
    "    #print(meanplot)\n",
    "    feat = list(meanplot.iloc[:n,0].values)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=1,shuffle=True)\n",
    "model=LogisticRegression(penalty='none')\n",
    "#model=DummyClassifier('most_frequent')\n",
    "from sklearn.linear_model import Lasso,RidgeClassifier,ElasticNet\n",
    "#model=ElasticNet()\n",
    "#model=GaussianNB()\n",
    "#model=RandomForestClassifier(n_estimators=100,n_jobs=-1,bootstrap=True,class_weight='balanced_subsample')\n",
    "#model=SGDClassifier('log',learning_rate='adaptive',eta0=0.005,class_weight='balanced')\n",
    "#model=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "#model=GradientBoostingClassifier(n_estimators=100)\n",
    "n_feat=[1,2,3,4,5,6,7,8,9,10]\n",
    "fin_roc=[]\n",
    "#X=X.drop(columns=['Diff_BL_1yr'])\n",
    "for f in n_feat:\n",
    "    print('\\nN Feat:',f)\n",
    "    \n",
    "    skf=StratifiedKFold(n_splits=10,random_state=4,shuffle=True)\n",
    "    skf1=StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "    loo=LeaveOneOut()\n",
    "    acc,f1,p,r,accb,roc,brier,mcc,lr_auc = [],[],[],[],[],[],[],[],[]\n",
    "    tot_feat={key:0 for key in X.columns}    \n",
    "    for train_index, test_index in skf1.split(X, Y):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = Y.iloc[train_index,:], Y.iloc[test_index,:]\n",
    "        y_p=[]\n",
    "        y_t=[]\n",
    "        feat={key:0 for key in X.columns}\n",
    "        for train_index, test_index in skf.split(X_train, y_train):\n",
    "            X_train_K, X_test_K = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "            y_train_K, y_test_K = y_train.iloc[train_index,:], y_train.iloc[test_index,:]\n",
    "\n",
    "\n",
    "            ###VARIABLE RANKING\n",
    "            rank={key:0 for key in X_train.columns}\n",
    "            for j in X_train.columns:\n",
    "                rank[j]=mannwhitneyu(X_train_K[y_train_K['Class']==0][j],X_train_K[y_train_K['Class']==1][j])[1]\n",
    "            rank={k: v for k, v in sorted(rank.items(), key=lambda item: item[1],reverse=False)}  \n",
    "            support=list(rank.keys())[0:f]\n",
    "            \n",
    "            #selector=RFE(LogisticRegression(class_weight='balanced'),f)\n",
    "            #selector=selector.fit(X_train_K,y_train_K.values.ravel())\n",
    "            #support=selector.support_\n",
    "            #support=feature_selection(f,X_train_K,y_train_K)\n",
    "            \n",
    "\n",
    "            ###INCREMENT FEATURE COUNTER\n",
    "            for j in X_train_K.loc[:,support].columns.to_list():\n",
    "                feat[j]+=1\n",
    "                tot_feat[j]+=1\n",
    "\n",
    "            ###SELECT BEST N FEAT\n",
    "            X_train_K = X_train_K.loc[:,support]\n",
    "            #X_test_K = X_test_K.loc[:,support]\n",
    "\n",
    "\n",
    "            ###SMOTE\n",
    "            under=RandomUnderSampler(0.5,random_state=0)\n",
    "            #oversample=SMOTE(sampling_strategy=1,k_neighbors=3,random_state=0)\n",
    "            #oversample=ADASYN(1,random_state=0)\n",
    "            #oversample=BorderlineSMOTE(1,k_neighbors=5,random_state=0)\n",
    "            oversample=SMOTENC(sampling_strategy=1,categorical_features=[i for i in range(f)],k_neighbors=10,random_state=10)\n",
    "            #X_train_K,y_train_K=under.fit_resample(X_train_K,y_train_K)\n",
    "            #X_train_K, y_train_K = oversample.fit_resample(X_train_K, y_train_K)\n",
    "\n",
    "\n",
    "\n",
    "            #model = model.fit(X_train_K,y_train_K.values.ravel())\n",
    "\n",
    "            #y_pred = model.predict(X_test_K)\n",
    "            #y_p.append(np.asscalar(y_pred))\n",
    "            #y_t.append(np.asscalar(y_test_K.values))\n",
    "\n",
    "\n",
    "        #print('TRAIN')\n",
    "        #print(accuracy_score(y_t,y_p))\n",
    "        #print(f1_score(y_t,y_p))\n",
    "        #print(precision_score(y_t,y_p))\n",
    "        #print(recall_score(y_t,y_p))\n",
    "        #print(balanced_accuracy_score(y_t,y_p))\n",
    "        #print(roc_auc_score(y_t,y_p))\n",
    "        \n",
    "\n",
    "\n",
    "        print('TEST')\n",
    "        tot_feat={k: v for k, v in sorted(tot_feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "        feat={k: v for k, v in sorted(feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "        print(list(feat.keys())[0:f])\n",
    "\n",
    "        X_train_ov=X_train.loc[:,list(feat.keys())[0:f]]\n",
    "        X_test_ov=X_test.loc[:,list(feat.keys())[0:f]]\n",
    "\n",
    "        \n",
    "        X_train_ov,y_train_ov=under.fit_resample(X_train_ov, y_train)\n",
    "        \n",
    "\n",
    "        X_train_ov['temp']=0\n",
    "        X_train_ov, y_train_ov = oversample.fit_resample(X_train_ov, y_train_ov)\n",
    "        X_train_ov=X_train_ov.drop(columns=['temp'])\n",
    "        \n",
    "        model=model.fit(X_train_ov,y_train_ov.values.ravel())\n",
    "        \n",
    "        y_pred=model.predict(X_test_ov)\n",
    "        y_prob=model.predict_proba(X_test_ov)[:,1]\n",
    "\n",
    "\n",
    "        acc.append(accuracy_score(y_test,y_pred))\n",
    "        f1.append(f1_score(y_test,y_pred))\n",
    "        p.append(precision_score(y_test,y_pred))\n",
    "        r.append(recall_score(y_test,y_pred))\n",
    "        accb.append(balanced_accuracy_score(y_test,y_pred))\n",
    "        roc.append(roc_auc_score(y_test,y_prob))\n",
    "        brier.append(brier_score_loss(y_test,y_pred))\n",
    "        mcc.append(matthews_corrcoef(y_test,y_pred))\n",
    "        lr_precision, lr_recall, thr = precision_recall_curve(y_test, y_prob)\n",
    "        lr_auc.append(auc(lr_recall, lr_precision))\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "    print('Acc:',np.mean(acc),'$\\\\pm$',np.std(acc))    \n",
    "    print('F1 mean',np.mean(f1))\n",
    "    print('Precision mean',np.mean(p))\n",
    "    print('Recall mean',np.mean(r))\n",
    "    print('Balance Acc mean',np.mean(accb))\n",
    "    try:\n",
    "        print('Roc AUC:',np.mean(roc))\n",
    "        print('PR AUC:',np.mean(lr_auc))\n",
    "        fin_roc.append(np.mean(roc))\n",
    "    except:\n",
    "        print('ROC AUC: Nan')\n",
    "    print('Brier',round(np.mean(brier),2))\n",
    "    print('MCC',round(np.mean(mcc),2))\n",
    "    print('\\n')\n",
    "    tot_feat={k: v for k, v in sorted(tot_feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "    print(tot_feat)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "plt.xlabel('N Feat')\n",
    "plt.ylabel('AUC ROC')\n",
    "plt.plot(n_feat,fin_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=1,shuffle=True)\n",
    "model=LogisticRegression(penalty='none')\n",
    "#model=DummyClassifier('most_frequent')\n",
    "from sklearn.linear_model import Lasso,RidgeClassifier,ElasticNet\n",
    "#model=ElasticNet()\n",
    "#model=GaussianNB()\n",
    "#model=RandomForestClassifier(n_estimators=100,n_jobs=-1,bootstrap=True,class_weight='balanced_subsample')\n",
    "#model=SGDClassifier('log',learning_rate='adaptive',eta0=0.005,class_weight='balanced')\n",
    "#model=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "#model=GradientBoostingClassifier(n_estimators=100)\n",
    "n_feat=[1,2,3,4,5,6,7,8,9,10]\n",
    "fin_roc=[]\n",
    "#X=X.drop(columns=['Diff_BL_1yr'])\n",
    "skf=StratifiedKFold(n_splits=10,random_state=4,shuffle=True)\n",
    "skf1=StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "loo=LeaveOneOut()\n",
    "acc,f1,p,r,accb,roc,brier,mcc,lr_auc = [],[],[],[],[],[],[],[],[]\n",
    "tot_feat={key:0 for key in X.columns}\n",
    "pippo=[]\n",
    "f=6\n",
    "for train_index, test_index in skf1.split(X, Y):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = Y.iloc[train_index,:], Y.iloc[test_index,:]\n",
    "    y_p=[]\n",
    "    y_t=[]\n",
    "    pluto=[]\n",
    "    feat={key:0 for key in X.columns}\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_K, X_test_K = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "        y_train_K, y_test_K = y_train.iloc[train_index,:], y_train.iloc[test_index,:]\n",
    "\n",
    "\n",
    "        ###VARIABLE RANKING\n",
    "        rank={key:0 for key in X_train.columns}\n",
    "        for j in X_train.columns:\n",
    "            rank[j]=mannwhitneyu(X_train_K[y_train_K['Class']==0][j],X_train_K[y_train_K['Class']==1][j])[1]\n",
    "        rank={k: v for k, v in sorted(rank.items(), key=lambda item: item[1],reverse=False)}  \n",
    "        support=list(rank.keys())[0:f]\n",
    "\n",
    "\n",
    "\n",
    "        ###INCREMENT FEATURE COUNTER\n",
    "        for j in X_train_K.loc[:,support].columns.to_list():\n",
    "            feat[j]+=1\n",
    "            tot_feat[j]+=1\n",
    "\n",
    "        ###SELECT BEST N FEAT\n",
    "        X_train_a = X_train_K.loc[:,support]\n",
    "        X_test_a = X_test_K.loc[:,support]\n",
    "\n",
    "\n",
    "        ###SMOTE\n",
    "        under=RandomUnderSampler(0.5,random_state=0)\n",
    "        oversample=SMOTENC(sampling_strategy=1,categorical_features=[i for i in range(f)],k_neighbors=10,random_state=10)\n",
    "        X_train_a,y_train_a=under.fit_resample(X_train_a,y_train_K)\n",
    "        X_train_a['temp']=0\n",
    "        X_train_a, y_train_a = oversample.fit_resample(X_train_a, y_train_a)\n",
    "        X_train_a=X_train_a.drop(columns=['temp'])\n",
    "\n",
    "\n",
    "\n",
    "        model = model.fit(X_train_a,y_train_a.values.ravel())\n",
    "\n",
    "        y_pred = model.predict_proba(X_test_a)[:,1]\n",
    "        pluto.append(roc_auc_score(y_test_K,y_pred))\n",
    "\n",
    "    pippo.append(np.mean(pluto))\n",
    "\n",
    "\n",
    "    print('TEST')\n",
    "    tot_feat={k: v for k, v in sorted(tot_feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "    feat={k: v for k, v in sorted(feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "    print(list(feat.keys())[0:f])\n",
    "\n",
    "    X_train_ov=X_train.loc[:,list(feat.keys())[0:f]]\n",
    "    X_test_ov=X_test.loc[:,list(feat.keys())[0:f]]\n",
    "\n",
    "\n",
    "    X_train_ov,y_train_ov=under.fit_resample(X_train_ov, y_train)\n",
    "\n",
    "\n",
    "    X_train_ov['temp']=0\n",
    "    X_train_ov, y_train_ov = oversample.fit_resample(X_train_ov, y_train_ov)\n",
    "    X_train_ov=X_train_ov.drop(columns=['temp'])\n",
    "\n",
    "    model=model.fit(X_train_ov,y_train_ov.values.ravel())\n",
    "\n",
    "    y_pred=model.predict(X_test_ov)\n",
    "    y_prob=model.predict_proba(X_test_ov)[:,1]\n",
    "\n",
    "\n",
    "    acc.append(accuracy_score(y_test,y_pred))\n",
    "    f1.append(f1_score(y_test,y_pred))\n",
    "    p.append(precision_score(y_test,y_pred))\n",
    "    r.append(recall_score(y_test,y_pred))\n",
    "    accb.append(balanced_accuracy_score(y_test,y_pred))\n",
    "    roc.append(roc_auc_score(y_test,y_prob))\n",
    "    brier.append(brier_score_loss(y_test,y_pred))\n",
    "    mcc.append(matthews_corrcoef(y_test,y_pred))\n",
    "    lr_precision, lr_recall, thr = precision_recall_curve(y_test, y_prob)\n",
    "    lr_auc.append(auc(lr_recall, lr_precision))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "print('Acc:',np.mean(acc),'$\\\\pm$',np.std(acc))    \n",
    "print('F1 mean',np.mean(f1))\n",
    "print('Precision mean',np.mean(p))\n",
    "print('Recall mean',np.mean(r))\n",
    "print('Balance Acc mean',np.mean(accb))\n",
    "try:\n",
    "    print('Roc AUC:',np.mean(roc))\n",
    "    print('PR AUC:',np.mean(lr_auc))\n",
    "    fin_roc.append(np.mean(roc))\n",
    "except:\n",
    "    print('ROC AUC: Nan')\n",
    "print('Brier',round(np.mean(brier),2))\n",
    "print('MCC',round(np.mean(mcc),2))\n",
    "print('\\n')\n",
    "tot_feat={k: v for k, v in sorted(tot_feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "print(tot_feat)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "plt.xlabel('N Feat')\n",
    "plt.ylabel('AUC ROC')\n",
    "#plt.plot(n_feat,fin_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=1,shuffle=True)\n",
    "model=LogisticRegression(class_weight='balanced')\n",
    "from sklearn.linear_model import Lasso,RidgeClassifier,ElasticNet\n",
    "#model=ElasticNet()\n",
    "#model=GaussianNB()\n",
    "#model=RandomForestClassifier(n_estimators=10,n_jobs=-1,bootstrap=True,class_weight='balanced_subsample')\n",
    "#model=SGDClassifier('log',learning_rate='adaptive',eta0=0.005,class_weight='balanced')\n",
    "#model=DecisionTreeClassifier(class_weight='balanced')\n",
    "n_feat=[1,2,3,4,5,6,7,8,9,10]\n",
    "fin_roc=[]\n",
    "#X=X.drop(columns=['Diff_BL_1yr'])\n",
    "for f in n_feat:\n",
    "    print('\\nN Feat:',f)\n",
    "    \n",
    "    skf=StratifiedKFold(n_splits=10,random_state=4,shuffle=True)\n",
    "    skf1=StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "    loo=LeaveOneOut()\n",
    "    acc,f1,p,r,accb,roc,brier,mcc = [],[],[],[],[],[],[],[]\n",
    "    tot_feat={key:0 for key in X.columns}    \n",
    "    for train_index, test_index in skf1.split(X, Y):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = Y.iloc[train_index,:], Y.iloc[test_index,:]\n",
    "        y_p=[]\n",
    "        y_t=[]\n",
    "        feat={key:0 for key in X.columns}\n",
    "        roc_val=0\n",
    "        for train_index, test_index in skf.split(X_train, y_train):\n",
    "            X_train_K, X_test_K = X_train.iloc[train_index,:], X_train.iloc[test_index,:]\n",
    "            y_train_K, y_test_K = y_train.iloc[train_index,:], y_train.iloc[test_index,:]\n",
    "\n",
    "\n",
    "            ###VARIABLE RANKING\n",
    "            rank={key:0 for key in X_train.columns}\n",
    "            for j in X_train.columns:\n",
    "                rank[j]=mannwhitneyu(X_train_K[y_train_K['Class']==0][j],X_train_K[y_train_K['Class']==1][j])[1]\n",
    "            rank={k: v for k, v in sorted(rank.items(), key=lambda item: item[1],reverse=False)}  \n",
    "            support=list(rank.keys())[0:f]\n",
    "            \n",
    "            #selector=RFE(LogisticRegression(class_weight='balanced'),f)\n",
    "            #selector=selector.fit(X_train_K,y_train_K.values.ravel())\n",
    "            #support=selector.support_\n",
    "            #support=feature_selection(f,X_train_K,y_train_K)\n",
    "            \n",
    "\n",
    "            ###INCREMENT FEATURE COUNTER\n",
    "            #for j in X_train_K.loc[:,support].columns.to_list():\n",
    "            #    feat[j]+=1\n",
    "            #    tot_feat[j]+=1\n",
    "\n",
    "            ###SELECT BEST N FEAT\n",
    "            X_train_K = X_train_K.loc[:,support]\n",
    "            X_test_K = X_test_K.loc[:,support]\n",
    "\n",
    "\n",
    "            ###SMOTE\n",
    "            under=RandomUnderSampler(0.5,random_state=0)\n",
    "            #oversample=SMOTE(sampling_strategy=1,k_neighbors=3,random_state=0)\n",
    "            #oversample=ADASYN(1,random_state=0)\n",
    "            #oversample=BorderlineSMOTE(1,k_neighbors=5,random_state=0)\n",
    "            oversample=SMOTENC(sampling_strategy=1,categorical_features=[i for i in range(f)],k_neighbors=10,random_state=10)\n",
    "            X_train_K,y_train_K=under.fit_resample(X_train_K,y_train_K)\n",
    "            \n",
    "            X_train_K['temp']=0\n",
    "            X_train_K, y_train_K = oversample.fit_resample(X_train_K, y_train_K)\n",
    "            X_train_K=X_train_K.drop(columns=['temp'])\n",
    "            model = model.fit(X_train_K,y_train_K.values.ravel())\n",
    "\n",
    "            y_pr_val = model.predict_proba(X_test_K)[:,1]\n",
    "            if roc_auc_score(y_test_K,y_pr_val) > roc_val:\n",
    "                roc_val=roc_auc_score(y_test_K,y_pr_val)\n",
    "                best=X_train_K.loc[:,support].columns.to_list()\n",
    "            #y_p.append(np.asscalar(y_pred))\n",
    "            #y_t.append(np.asscalar(y_test_K.values))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        print('TEST')\n",
    "        for j in X_train.loc[:,best].columns.to_list():\n",
    "            tot_feat[j]+=1\n",
    "        tot_feat={k: v for k, v in sorted(tot_feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "        print(best)\n",
    "        X_train_ov=X_train.loc[:,best]\n",
    "        X_test_ov=X_test.loc[:,best]\n",
    "        \n",
    "        X_train_ov,y_train_ov=under.fit_resample(X_train_ov, y_train)\n",
    "        \n",
    "\n",
    "        X_train_ov['temp']=0\n",
    "        X_train_ov, y_train_ov = oversample.fit_resample(X_train_ov, y_train_ov)\n",
    "        X_train_ov=X_train_ov.drop(columns=['temp'])\n",
    "        \n",
    "        model=model.fit(X_train_ov,y_train_ov.values.ravel())\n",
    "        \n",
    "        y_pred=model.predict(X_test_ov)\n",
    "        y_prob=model.predict_proba(X_test_ov)[:,1]\n",
    "\n",
    "        acc.append(accuracy_score(y_test,y_pred))\n",
    "        f1.append(f1_score(y_test,y_pred))\n",
    "        p.append(precision_score(y_test,y_pred))\n",
    "        r.append(recall_score(y_test,y_pred))\n",
    "        accb.append(balanced_accuracy_score(y_test,y_pred))\n",
    "        roc.append(roc_auc_score(y_test,y_prob))\n",
    "        brier.append(brier_score_loss(y_test,y_pred))\n",
    "        mcc.append(matthews_corrcoef(y_test,y_pred))\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "    print('Acc mean',np.mean(acc))    \n",
    "    print('F1 mean',np.mean(f1))\n",
    "    print('Precision mean',np.mean(p))\n",
    "    print('Recall mean',np.mean(r))\n",
    "    print('Balance Acc mean',np.mean(accb))\n",
    "    try:\n",
    "        print('Roc AUC:',np.mean(roc))\n",
    "        fin_roc.append(np.mean(roc))\n",
    "    except:\n",
    "        print('ROC AUC: Nan')\n",
    "    print('Brier',np.mean(brier))\n",
    "    print('MCC',np.mean(mcc))\n",
    "    print('\\n')\n",
    "    tot_feat={k: v for k, v in sorted(tot_feat.items(), key=lambda item: item[1],reverse=True)}\n",
    "    print(tot_feat)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "plt.xlabel('N Feat')\n",
    "plt.ylabel('AUC ROC')\n",
    "plt.plot(n_feat,fin_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [20, 30, 40, 50 ,60, 70, 80]\n",
    "sampling = random.choices(list, k=4)\n",
    "sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "#ADD 2yr-1yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loo=LeaveOneOut()\n",
    "models=[LogisticRegression(class_weight='balanced')]\n",
    "#models=[RandomForestClassifier(n_estimators=10,n_jobs=-1,bootstrap=True,class_weight='balanced_subsample')]\n",
    "#models=[SGDClassifier('log',learning_rate='adaptive',eta0=0.005,class_weight='balanced')]\n",
    "#models=[DecisionTreeClassifier(class_weight='balanced')]\n",
    "#model=[Lasso()]\n",
    "#model=[GaussianNB()]\n",
    "model_names=['LOG']\n",
    "import random\n",
    "import math\n",
    "roc=[]\n",
    "tot_comb=[]\n",
    "def ev(var):\n",
    "    X_f=X.loc[:,var]\n",
    "    print(list(X_f.columns))\n",
    "    y_t,y_p=[],[]\n",
    "    for model,model_name in zip(models,model_names):\n",
    "        acc,f1,p,r,accb,roc = [],[],[],[],[],[]\n",
    "        y_p=[]\n",
    "        Y_prob=[]\n",
    "        y_t=[]\n",
    "        for train_index, test_index in loo.split(X_f, Y):\n",
    "            X_train_K, X_test_K = X_f.iloc[train_index,:], X_f.iloc[test_index,:]\n",
    "            y_train_K, y_test_K = Y.iloc[train_index,:], Y.iloc[test_index,:]\n",
    "            under=RandomUnderSampler(0.5,random_state=1)\n",
    "            oversample=SMOTENC(categorical_features=[i for i in range(len(X_train_K.columns))],\n",
    "                               sampling_strategy=1,k_neighbors=10,random_state=1)\n",
    "\n",
    "\n",
    "            X_train_ov,y_train_ov=under.fit_resample(X_train_K, y_train_K)\n",
    "            X_train_ov['temp']=0\n",
    "            X_train_ov, y_train_ov = oversample.fit_resample(X_train_ov, y_train_ov)\n",
    "            X_train_ov=X_train_ov.drop(columns=['temp'])\n",
    "\n",
    "            model.fit(X_train_K,y_train_K.values.ravel())\n",
    "            y_pred = model.predict(X_test_K)\n",
    "            y_p.append(y_pred.item())\n",
    "            Y_prob.append(list(model.predict_proba(X_test_K).ravel()))\n",
    "            y_t.append(y_test_K.values.item())\n",
    "            \n",
    "            \n",
    "    Y_prob=np.array(Y_prob)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    fpr, tpr, _ = roc_curve(y_t, Y_prob[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('ROC',roc_auc)\n",
    "    print('ROC',roc_auc_score(y_t,Y_prob[:,1]))\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('ROC_6var')\n",
    "    plt.show()\n",
    "\n",
    "    print('\\n')\n",
    "    \n",
    "    lr_precision, lr_recall, thr = precision_recall_curve(y_t, Y_prob[:,1])\n",
    "    lr_auc = auc(lr_recall, lr_precision)\n",
    "    print('Logistic: auc=%.3f' % (lr_auc))\n",
    "    # plot the precision-recall curves\n",
    "    no_skill = np.size(y_t[y_t==1]) / np.size(len(y_t))\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
    "    plt.plot(thr,lr_precision[:-1],\"b--\",label='Precision')\n",
    "    plt.plot(thr,lr_recall[:-1],\"g-\",label='Recall')\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print('ACC',accuracy_score(y_t,y_p))\n",
    "    print('F1',f1_score(y_t,y_p))\n",
    "    print('PREC',precision_score(y_t,y_p))\n",
    "    print('REC',recall_score(y_t,y_p))\n",
    "    print('BAL ACC',balanced_accuracy_score(y_t,y_p))\n",
    "    \n",
    "    print(confusion_matrix(y_t,y_p))\n",
    "    model=model.fit(X_f,Y)\n",
    "    print(model.coef_[0])\n",
    "    print(model.intercept_)\n",
    "\n",
    "    return roc_auc_score(y_t,Y_prob[:,1]),var\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "variables=['Diff_BL_1yr', 'DiffAxial_Sub_1', 'DiffTremor_Sub', 'DiffLimb_Rig_Sub',\n",
    "                     'DiffCommon_daily_act', 'DiffBulbar']\n",
    "x,y=ev(variables)\n",
    "roc.append(x)\n",
    "tot_comb.append(y)\n",
    "\n",
    "\n",
    "var_add=['BMI_x', 'DiffEpworth_SUM', 'DiffGait', 'SCOPA_TOT_x', 'Cognitive_x','gen']\n",
    "\n",
    "for j in range(len(var_add)):\n",
    "    sampling1=var_add[j]\n",
    "    x,y=ev(variables+[sampling1])\n",
    "    roc.append(x)\n",
    "    tot_comb.append(y)\n",
    "    for z in range(j+1,len(var_add)):\n",
    "        sampling2=var_add[z]\n",
    "        x,y=ev(variables+[sampling1,sampling2])\n",
    "        roc.append(x)\n",
    "        tot_comb.append(y)\n",
    "plt.plot([i for i in range(len(roc))],roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.69060146 ,0.19562998, 0.34653553, 0.085848, 0.16140227, 0.58873592]\n",
    "np.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=roc.index(max(roc))\n",
    "print(tot_comb[index],max(roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=7)\n",
    "X_PCA=pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(class_weight='balanced')\n",
    "loo=LeaveOneOut()\n",
    "y_p,y_t,y_prob=[],[],[]\n",
    "for train_index, test_index in loo.split(X_PCA, Y):\n",
    "        X_train_K, X_test_K = X_PCA[train_index,:], X_PCA[test_index,:]\n",
    "        y_train_K, y_test_K = Y.iloc[train_index,:], Y.iloc[test_index,:]\n",
    "        under=RandomUnderSampler(0.5,random_state=1)\n",
    "        #oversample=SMOTENC(categorical_features=[i for i in range(len(X_train_K.columns))],\n",
    "        #                   sampling_strategy=1,k_neighbors=10,random_state=1)\n",
    "\n",
    "\n",
    "        #X_train_ov,y_train_ov=under.fit_resample(X_train_K, y_train_K)\n",
    "        #X_train_ov['temp']=0\n",
    "        #X_train_ov, y_train_ov = oversample.fit_resample(X_train_ov, y_train_ov)\n",
    "        #X_train_ov=X_train_ov.drop(columns=['temp'])\n",
    "\n",
    "        model.fit(X_train_K,y_train_K.values.ravel())\n",
    "        y_pred = model.predict(X_test_K)\n",
    "        y_prob.append(model.predict_proba(X_test_K)[0][1])\n",
    "        y_p.append(y_pred.item())\n",
    "        y_t.append(y_test_K.values.item())\n",
    "print('ACC',accuracy_score(y_t,y_p))\n",
    "print('F1',f1_score(y_t,y_p))\n",
    "print('PREC',precision_score(y_t,y_p))\n",
    "print('REC',recall_score(y_t,y_p))\n",
    "print('BAL ACC',balanced_accuracy_score(y_t,y_p))\n",
    "print('ROC',roc_auc_score(y_t,y_prob))\n",
    "print(confusion_matrix(y_t,y_p))\n",
    "#model=model.fit(X_f,Y)\n",
    "#print(model.coef_[0])\n",
    "#print(model.intercept_)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}